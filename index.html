<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="Start your development with Ollie landing page.">
    <meta name="author" content="Devcrud">
    <title>Finishing Project</title>

    <!-- font icons -->
    <link rel="stylesheet" href="assets/vendors/themify-icons/css/themify-icons.css">

    <!-- owl carousel -->
    <link rel="stylesheet" href="assets/vendors/owl-carousel/css/owl.carousel.css">
    <link rel="stylesheet" href="assets/vendors/owl-carousel/css/owl.theme.default.css">

    <!-- Bootstrap + Ollie main styles -->
    <link rel="stylesheet" href="assets/css/ollie.css">

</head>

<body data-spy="scroll" data-target=".navbar" data-offset="40" id="home">

    <nav id="scrollspy" class="navbar navbar-light bg-light navbar-expand-lg fixed-top" data-spy="affix"
        data-offset-top="20">
        <div class="container">
            <a class="navbar-brand" href="#"><img src="assets/imgs/brand.svg" alt="" class="brand-img"></a>
            <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#navbarSupportedContent"
                aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>

            <div class="collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav ml-auto">
                    <li class="nav-item">
                        <a class="nav-link" href="#home">Home</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#about">Contributors</a>
                    </li>
                    <!-- <li class="nav-item">
                        <a class="nav-link" href="#portfolio">Proposal</a>
                    </li> -->
                    <li class="nav-item">
                        <a class="nav-link" href="#testmonial">Proposal</a>
                    </li>
                    <li class="nav-item">
                        <a class="nav-link" href="#blog">Updates</a>
                    </li>


                </ul>
            </div>
        </div>
    </nav>


    <header id="home" class="header">
        <div class="overlay"></div>

        <div id="header-carousel" class="carousel slide carousel-fade" data-ride="carousel">
            <div class="container">
                <div class="carousel-inner">
                    <div class="carousel-item active">
                        <div class="carousel-caption d-none d-md-block">
                            <h1 class="carousel-title">Improving Images <br>Distorted by Fog and Haze</h1>
                            
                        </div>
                    </div>

                </div>
            </div>
        </div>
    </header>

    <section class="section" id="about">

        <div class="container">

            <div class="row align-items-center mr-auto">
                <div class="col-md-4">
                    <h6 class="xs-font mb-0">Supervisor</h6>
                    <br>
                    <img src="assets\imgs\download.png" alt="Hocam" width="70" height="70" style="border-radius: 50%;">
                    <h3 class="section-title">Emin Kugu</h3>



                </div>
                <div class="col-sm-6 col-md-4 ml-auto">
                    <div class="widget">
                        <div class="icon-wrapper">
                            <i class="ti-user"></i>
                        </div>
                        <div class="infos-wrapper">
                            <h4 class="text-primary">Member</h4>
                            <p>ENES YARDIM</p>
                        </div>
                    </div>
                    <div class="widget">
                        <div class="icon-wrapper">
                            <i class="ti-user"></i>
                        </div>
                        <div class="infos-wrapper">
                            <h4 class="text-primary">Member</h4>
                            <p>ABDUSSELAM KOÇ</p>
                        </div>
                    </div>
                </div>
                <div class="col-sm-6 col-md-4">
                    <div class="widget">
                        <div class="icon-wrapper">
                            <i class="ti-user"></i>
                        </div>
                        <div class="infos-wrapper">
                            <h4 class="text-primary">Member</h4>
                            <p>BAHADIR ÜNAL</p>
                        </div>
                    </div>
                    <div class="widget">
                        <div class="icon-wrapper">
                            <i class="ti-user"></i>
                        </div>
                        <div class="infos-wrapper">
                            <h4 class="text-primary">Member</h4>
                            <p>OĞUZ ÖZTÜRK</p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>





    <section class="section" id="testmonial">
        <div class="container">
<br>
<br>
            <h3 class="section-title">Improving Images Distorted by Fog and Haze</h3>
            <p>Effects such as fog, dust, smoke, haze, rain, snow, and low light that occur naturally or artificially in
                our environment limit the ability to see. These effects, which impair the ability to see, are
                significant problems that make life difficult for people. In order to act early and on time, it is
                necessary to recognize the external situation and the danger in the environment, if any. In a case where
                the view is partially or completely limited, the decrease in awareness creates problems in terms of
                security and perception. The attacks carried out by terrorists in the field of defense in foggy and
                rainy weather conditions are the most important examples of this problem. In addition, various problems
                and disruptions are experienced in transportation in bad weather conditions.
                <br>
                <br>
                The issue of completely or partially removing effects on images obtained in fog and haze conditions is a
                subject that has been studied for many years and has rich literature. In defogging operation when the
                distance between the display device and the scene increases, the fog/haze thickness increases, and the
                transmission of the media decreases. Similarly, when the fog/haze density is high and varies locally,
                the complexity of the fog removal process increases. There are many ways to remove fog and haze, but
                these are generally contrasted enhancement (Jia et al. 2020; Sammaraie 2015; Kim et al. 2011; Cai et al.
                2011), restoration (Tan and Oakley 2001; Tang et al., 2014; Gibson et al., 2013; Fang et al., 2014;
                Galdran et al., 2015) and fusion-based (Son et al., 2015; Ancuti and Ancuti 2015; Guo et al., 2020;
                Zhang et al., 2014; Simeng and Qinghua 2021) methods. can be grouped into categories. Contrast
                enhancement approaches aim to improve the visual quality of hazy images to some extent; however, they
                cannot effectively remove the fog. Subcategories of image enhancement models, histogram enhancement that
                can be applied locally and/or globally (Simi et al., 2020; Joseph and Periyasamy, 2018; Joseph et al.,
                2017), frequency conversion methods: wavelet transform and homomorphic filtering, and Retinex method:
                single and multiscale Retinex (Hao et al. 2011). Restoration-based methods focus on recovering lost
                information by modeling the image degradation pattern and applying inverse filtering. The atmospheric
                light scattering model is one of the most widely used models in image fog removal, and the physical
                equivalent of this model is given in Figure 3.
                <br>
                <br>
                <img src="assets\imgs\Image.png" alt="aciklama">
                <br>
                <br>
                The most important point in this model is the accurate estimation of the transmission rate and
                atmospheric light. The formula used in this case is given in the table above. (Cimtay, 2021).

                In this formula, H(x, λ) represents the foggy/hazy picture, and T(x, λ) is the illumination value
                reflected from the scene and transmitted through the fog layer. AL(x, λ) represents air light reflected
                from the fog. The sensor collects the incoming lights, and the resulting image is the foggy/hazy image
                obtained. In Equation 2, t(x, λ) represents the transmission value from the fog, RL(x, λ) represents the
                light reflected from the scene and L∞ represents the atmospheric light. The transmission component is
                calculated as e^(-α(λ)d(x)). Here d(x) is the scene depth map and α (λ) is the wavelength-dependent
                scattering term coefficient.
                The Dark Channel Prior (DCP) Method (Kaiming et al. 2011) is one of the most widely used methods, using
                the dark channel per pixel. At the same time, quadtree decomposition was applied to measure atmospheric
                light. Another study based on DCP is (by Park et al. 2014). In this study, both pixel-based processing
                and similarity between spatial blocks were used to calculate the dark channel.
                <br>
                <br>
                Recent approaches to defogging are mostly based on artificial intelligence approaches using deep
                learning models (Li et al., 2018; Li et al. 2018; Haouassi and Di, 2020). In (Cai et al. 2016), a deep
                architecture was developed using CNN, and a new unit called “bidirectional rectified linear unit” was
                added to the neural network. Better results were obtained in this study compared to previous studies.
                The work of (Rashid et al. 2019) used the end-to-end encoder-decoder CNN architecture to obtain fog-free
                images. In addition to the methods of defogging on a single image, methods that defog using video data
                are also used. For example, the study by (Ren et al. 2019) took advantage of the temporal similarity
                between consecutive video frames and trained the video data over CNN, assuming that atmospheric effects
                would be similar as a result of this similarity. In this way, it did the defogging process in the
                videos. In addition, in the study of (Dong et al., 2019), video defog was effectively performed by
                utilizing the Spatio-temporal similarity between video frames on the basis of DCP.
                <br>
                <br>
                In addition to images taken in RGB band gaps, fog removal processes were applied to foggy images taken
                in Short Wave Infrared (SWIR) and Long Wave Infrared (LWIR) bands (argosfp7project, 2020). In these
                studies, fog reduction was performed using hyperspectral SWIR cameras (widy-swir-640, 2020). In
                (widy-swir-640, 2020) an application that performs fog reduction in the SWIR band shown in Figure 4 is
                exemplified. In these cameras, the bands that provide the best vision in the fog were selected and the
                improvement process was made. However, such cameras are quite expensive and difficult to manufacture
                (OEM cameras, 2021; FLIR-direct, 2021). Such camera prices are currently around $15,000. Therefore, this
                project, it is aimed to successfully remove fog, haze, dust, and smoke from traditional RGB images.
                Because both products will be low-cost and can be easily integrated into all systems running on RGB
                tape, which is currently used in transportation, security, first aid, monitoring, and surveillance.
                <br>
                <br>
                In this study, artificial intelligence-based methods and especially the use of CapsuleNetworks and
                GraphNN structures, which have not yet been implemented in the literature, will be emphasized in order
                to improve foggy and hazy images. In this way, it is considered that much more successful fog and haze
                removal can be achieved, especially in situations where intense disruptive effects are dominant.
            </p>


        </div>
    </section>



    <section class="section" id="blog">

        <div class="container mb-3">
            
            <h3 class="section-title mb-5">Our Blog</h3>

            <div class="blog-wrapper">
                <div class="img-wrapper">
                    <img src="assets/imgs/img-3.jpg"
                        alt="Download free bootstrap 4 landing page, free boootstrap 4 templates, Download free bootstrap 4.1 landing page, free boootstrap 4.1.1 templates, ollie Landing page">
                    <div class="date-container">
                        <h6 class="day">29</h6>
                        <h6 class="mun">Jun</h6>
                    </div>
                </div>
                <div class="txt-wrapper">
                    <h4 class="blog-title">Updates</h4>
                    <p>No update now. It is version 1.0 </p>


                </div>


            </div>
        </div>
    </section>



    <!-- core  -->
    <script src="assets/vendors/jquery/jquery-3.4.1.js"></script>
    <script src="assets/vendors/bootstrap/bootstrap.bundle.js"></script>

    <!-- bootstrap 3 affix -->
    <script src="assets/vendors/bootstrap/bootstrap.affix.js"></script>

    <!-- Owl carousel  -->
    <script src="assets/vendors/owl-carousel/js/owl.carousel.js"></script>


    <!-- Ollie js -->
    <script src="assets/js/Ollie.js"></script>

</body>

</html>